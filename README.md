# LLM Evaluation Platform

A modular, extensible platform for evaluating LLM and RAG systems using
metrics like relevance, faithfulness, completeness, and hallucination.

## Features
- Model-agnostic evaluation
- Dataset-driven scoring
- Metric-based verdicts
- Designed for regression testing of LLM outputs

## Tech Stack
- Python
- FastAPI (planned)
- Sentence Transformers
- FAISS (optional)

## Status
ðŸš§ In active development
